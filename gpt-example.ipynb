{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom transformers import (\n    GPT2Tokenizer,\n    GPT2LMHeadModel,\n    LogitsProcessorList,\n    MinLengthLogitsProcessor,\n    TopKLogitsWarper,\n    TopPLogitsWarper,\n    StoppingCriteriaList,\n    MaxLengthCriteria\n)\nimport nltk\nfrom nltk.tokenize import sent_tokenize\nnltk.download('punkt')\n\n\n\nmodel_name = \"gpt2\"\ntokenizer = GPT2Tokenizer.from_pretrained(model_name)\nmodel = GPT2LMHeadModel.from_pretrained(model_name)\nmodel.eval()\n\n\nif torch.cuda.is_available():\n    model.cuda()\n\n\nprompt = \"In a world where AI governs everything, humanity\"\n\n\ninput_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\ninput_ids = input_ids.cuda() if torch.cuda.is_available() else input_ids\n\n\ntop_k = 50\n# The model will select the next word from the top 50 most probable tokens.\n# This is part of Top-K Sampling, which restricts the model to a set of most likely tokens.\ntop_p = 0.95\n# This parameter is for Top-P (nucleus) Sampling, which means the model will select the next token from the smallest\n# set of tokens that together have a cumulative probability of 0.95.\ntemperature = 0.8\n# Controls the randomness of the output. Lower values make the model more deterministic, while higher values (close to 1) make the generation more diverse.\nmax_new_tokens = 100 # The maximum number of tokens to generate beyond the input prompt.\n\n\nprocessors = LogitsProcessorList([\n    MinLengthLogitsProcessor(min_length=40, eos_token_id=tokenizer.eos_token_id),\n    TopKLogitsWarper(top_k),\n    TopPLogitsWarper(top_p)\n])\n\n# MinLengthLogitsProcessor: Ensures that the generated text is at least 40 tokens long.\n\n# TopKLogitsWarper: Limits the selection of next tokens to the top k logits (50 tokens in this case).\n\nwith torch.no_grad():\n    output = model.generate(\n        input_ids,\n        max_new_tokens=max_new_tokens,\n        temperature=temperature,\n        logits_processor=processors,\n        stopping_criteria=StoppingCriteriaList([\n            MaxLengthCriteria(max_length=len(input_ids[0]) + max_new_tokens)\n        ]),\n        do_sample=True,\n        pad_token_id=tokenizer.eos_token_id\n    )\n\n\ngenerated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n\nprint(\"\\n--- Story Generated ---\\n\")\nprint(generated_text)\n\nkeywords = [\"AI\", \"freedom\", \"resistance\"]\nbanned = [\"blood\", \"kill\", \"murder\"]\n\nprint(\"\\n--- Keyword/Banned Word Analysis ---\\n\")\nsentences = sent_tokenize(generated_text)\nfor sent in sentences:\n    hits = [kw for kw in keywords if kw.lower() in sent.lower() and kw.lower()]\n    bans = [bw for bw in banned if bw.lower() in sent.lower()]\n    if hits or bans:\n        print(f\"Sentence: {sent}\")\n        if hits:\n            print(f\"Keywords found: {hits}\")\n        if bans:\n            print(f\"Banned words found: {bans}\")\n        print()\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-16T23:47:31.184654Z","iopub.execute_input":"2025-04-16T23:47:31.185331Z","iopub.status.idle":"2025-04-16T23:47:33.224114Z","shell.execute_reply.started":"2025-04-16T23:47:31.185302Z","shell.execute_reply":"2025-04-16T23:47:33.223244Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"name":"stdout","text":"\n--- Story Generated ---\n\nIn a world where AI governs everything, humanity will need to change its own behavior and make more intelligent decisions. In other words, the human population will have to adapt quickly. However, that is the only way that AI will take over.\n\n--- Keyword/Banned Word Analysis ---\n\nSentence: In a world where AI governs everything, humanity will need to change its own behavior and make more intelligent decisions.\nKeywords found: ['AI']\n\nSentence: However, that is the only way that AI will take over.\nKeywords found: ['AI']\n\n","output_type":"stream"}],"execution_count":8}]}